{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "from scipy.misc import imsave\n",
    "import os\n",
    "import shutil\n",
    "from PIL import Image\n",
    "import time\n",
    "import random\n",
    "import sys\n",
    "\n",
    "from layers import *\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_height = 256\n",
    "img_width = 256\n",
    "img_layer = 3\n",
    "img_size = img_height * img_width\n",
    "\n",
    "to_train = False\n",
    "to_test = True\n",
    "to_restore = False\n",
    "output_path = \"./output\"\n",
    "check_dir = \"./output/checkpoints/\"\n",
    "\n",
    "temp_check = 0\n",
    "\n",
    "max_epoch = 1\n",
    "max_images = 100\n",
    "\n",
    "h1_size = 150\n",
    "h2_size = 300\n",
    "z_size = 100\n",
    "batch_size = 1\n",
    "pool_size = 50\n",
    "sample_size = 10\n",
    "save_training_images = True\n",
    "ngf = 32\n",
    "ndf = 64\n",
    "\n",
    "\n",
    "class CycleGAN():\n",
    "\n",
    "    def input_setup(self):\n",
    "\n",
    "        ''' \n",
    "        This function basically setup variables for taking image input.\n",
    "        filenames_A/filenames_B -> takes the list of all training images\n",
    "        self.image_A/self.image_B -> Input image with each values ranging from [-1,1]\n",
    "        '''\n",
    "\n",
    "        filenames_A = tf.train.match_filenames_once(\"./input/trainA/*.jpg\")    \n",
    "        self.queue_length_A = tf.size(filenames_A)\n",
    "        filenames_B = tf.train.match_filenames_once(\"./input/trainB/*.jpg\")    \n",
    "        self.queue_length_B = tf.size(filenames_B)\n",
    "\n",
    "        filename_queue_A = tf.train.string_input_producer(filenames_A)\n",
    "        filename_queue_B = tf.train.string_input_producer(filenames_B)\n",
    "\n",
    "        image_reader = tf.WholeFileReader()\n",
    "        _, image_file_A = image_reader.read(filename_queue_A)\n",
    "        _, image_file_B = image_reader.read(filename_queue_B)\n",
    "\n",
    "        self.image_A = tf.subtract(\n",
    "            tf.div(tf.image.resize_images(tf.image.decode_jpeg(image_file_A), [256, 256]), 127.5), 1)\n",
    "        self.image_B = tf.subtract(\n",
    "            tf.div(tf.image.resize_images(tf.image.decode_jpeg(image_file_B), [256, 256]), 127.5), 1)\n",
    "\n",
    "    def input_read(self, sess):\n",
    "\n",
    "        '''\n",
    "        It reads the input into from the image folder.\n",
    "        self.fake_images_A/self.fake_images_B -> List of generated images used for calculation of loss function of Discriminator\n",
    "        self.A_input/self.B_input -> Stores all the training images in python list\n",
    "        '''\n",
    "\n",
    "        # Loading images into the tensors\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord)\n",
    "\n",
    "        num_files_A = sess.run(self.queue_length_A)\n",
    "        num_files_B = sess.run(self.queue_length_B)\n",
    "\n",
    "        self.fake_images_A = np.zeros((pool_size, 1, img_height, img_width, img_layer))\n",
    "        self.fake_images_B = np.zeros((pool_size, 1, img_height, img_width, img_layer))\n",
    "\n",
    "        self.A_input = np.zeros((max_images, batch_size, img_height, img_width, img_layer))\n",
    "        self.B_input = np.zeros((max_images, batch_size, img_height, img_width, img_layer))\n",
    "\n",
    "        for i in range(max_images):\n",
    "            image_tensor = sess.run(self.image_A)\n",
    "            if (image_tensor.size == img_size * batch_size * img_layer):\n",
    "                self.A_input[i] = image_tensor.reshape((batch_size, img_height, img_width, img_layer))\n",
    "\n",
    "        for i in range(max_images):\n",
    "            image_tensor = sess.run(self.image_B)\n",
    "            if (image_tensor.size == img_size * batch_size * img_layer):\n",
    "                self.B_input[i] = image_tensor.reshape((batch_size, img_height, img_width, img_layer))\n",
    "\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "\n",
    "    def model_setup(self):\n",
    "\n",
    "        ''' This function sets up the model to train\n",
    "        self.input_A/self.input_B -> Set of training images.\n",
    "        self.fake_A/self.fake_B -> Generated images by corresponding generator of input_A and input_B\n",
    "        self.lr -> Learning rate variable\n",
    "        self.cyc_A/ self.cyc_B -> Images generated after feeding self.fake_A/self.fake_B to corresponding generator. This is use to calcualte cyclic loss\n",
    "        '''\n",
    "\n",
    "        self.input_A = tf.placeholder(tf.float32, [batch_size, img_width, img_height, img_layer], name=\"input_A\")\n",
    "        self.input_B = tf.placeholder(tf.float32, [batch_size, img_width, img_height, img_layer], name=\"input_B\")\n",
    "\n",
    "        self.fake_pool_A = tf.placeholder(tf.float32, [None, img_width, img_height, img_layer], name=\"fake_pool_A\")\n",
    "        self.fake_pool_B = tf.placeholder(tf.float32, [None, img_width, img_height, img_layer], name=\"fake_pool_B\")\n",
    "\n",
    "        self.global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "\n",
    "        self.num_fake_inputs = 0\n",
    "\n",
    "        self.lr = tf.placeholder(tf.float32, shape=[], name=\"lr\")\n",
    "\n",
    "        with tf.variable_scope(\"Model\") as scope:\n",
    "            self.fake_B = build_generator_resnet_9blocks(self.input_A, name=\"g_A\")\n",
    "            self.fake_A = build_generator_resnet_9blocks(self.input_B, name=\"g_B\")\n",
    "            self.rec_A = build_gen_discriminator(self.input_A, \"d_A\")\n",
    "            self.rec_B = build_gen_discriminator(self.input_B, \"d_B\")\n",
    "\n",
    "            scope.reuse_variables()\n",
    "\n",
    "            self.fake_rec_A = build_gen_discriminator(self.fake_A, \"d_A\")\n",
    "            self.fake_rec_B = build_gen_discriminator(self.fake_B, \"d_B\")\n",
    "            self.cyc_A = build_generator_resnet_9blocks(self.fake_B, \"g_B\")\n",
    "            self.cyc_B = build_generator_resnet_9blocks(self.fake_A, \"g_A\")\n",
    "\n",
    "            scope.reuse_variables()\n",
    "\n",
    "            self.fake_pool_rec_A = build_gen_discriminator(self.fake_pool_A, \"d_A\")\n",
    "            self.fake_pool_rec_B = build_gen_discriminator(self.fake_pool_B, \"d_B\")\n",
    "\n",
    "    def loss_calc(self):\n",
    "\n",
    "        ''' In this function we are defining the variables for loss calcultions and traning model\n",
    "        d_loss_A/d_loss_B -> loss for discriminator A/B\n",
    "        g_loss_A/g_loss_B -> loss for generator A/B\n",
    "        *_trainer -> Variaous trainer for above loss functions\n",
    "        *_summ -> Summary variables for above loss functions'''\n",
    "\n",
    "        cyc_loss = tf.reduce_mean(tf.abs(self.input_A - self.cyc_A)) + tf.reduce_mean(tf.abs(self.input_B - self.cyc_B))\n",
    "\n",
    "        disc_loss_A = tf.reduce_mean(tf.squared_difference(self.fake_rec_A, 1))\n",
    "        disc_loss_B = tf.reduce_mean(tf.squared_difference(self.fake_rec_B, 1))\n",
    "\n",
    "        g_loss_A = cyc_loss * 10 + disc_loss_B\n",
    "        g_loss_B = cyc_loss * 10 + disc_loss_A\n",
    "\n",
    "        d_loss_A = (tf.reduce_mean(tf.square(self.fake_pool_rec_A)) + tf.reduce_mean(\n",
    "            tf.squared_difference(self.rec_A, 1))) / 2.0\n",
    "        d_loss_B = (tf.reduce_mean(tf.square(self.fake_pool_rec_B)) + tf.reduce_mean(\n",
    "            tf.squared_difference(self.rec_B, 1))) / 2.0\n",
    "\n",
    "        optimizer = tf.train.AdamOptimizer(self.lr, beta1=0.5)\n",
    "\n",
    "        self.model_vars = tf.trainable_variables()\n",
    "\n",
    "        d_A_vars = [var for var in self.model_vars if 'd_A' in var.name]\n",
    "        g_A_vars = [var for var in self.model_vars if 'g_A' in var.name]\n",
    "        d_B_vars = [var for var in self.model_vars if 'd_B' in var.name]\n",
    "        g_B_vars = [var for var in self.model_vars if 'g_B' in var.name]\n",
    "\n",
    "        self.d_A_trainer = optimizer.minimize(d_loss_A, var_list=d_A_vars)\n",
    "        self.d_B_trainer = optimizer.minimize(d_loss_B, var_list=d_B_vars)\n",
    "        self.g_A_trainer = optimizer.minimize(g_loss_A, var_list=g_A_vars)\n",
    "        self.g_B_trainer = optimizer.minimize(g_loss_B, var_list=g_B_vars)\n",
    "\n",
    "        for var in self.model_vars: print(var.name)\n",
    "\n",
    "        # Summary variables for tensorboard\n",
    "\n",
    "        self.g_A_loss_summ = tf.summary.scalar(\"g_A_loss\", g_loss_A)\n",
    "        self.g_B_loss_summ = tf.summary.scalar(\"g_B_loss\", g_loss_B)\n",
    "        self.d_A_loss_summ = tf.summary.scalar(\"d_A_loss\", d_loss_A)\n",
    "        self.d_B_loss_summ = tf.summary.scalar(\"d_B_loss\", d_loss_B)\n",
    "\n",
    "    def save_training_images(self, sess, epoch):\n",
    "\n",
    "        if not os.path.exists(\"./output/imgs\"):\n",
    "            os.makedirs(\"./output/imgs\")\n",
    "\n",
    "        for i in range(0, 10):\n",
    "            fake_A_temp, fake_B_temp, cyc_A_temp, cyc_B_temp = sess.run(\n",
    "                [self.fake_A, self.fake_B, self.cyc_A, self.cyc_B],\n",
    "                feed_dict={self.input_A: self.A_input[i], self.input_B: self.B_input[i]})\n",
    "            imsave(\"./output/imgs/fakeB_\" + str(epoch) + \"_\" + str(i) + \".jpg\",\n",
    "                   ((fake_A_temp[0] + 1) * 127.5).astype(np.uint8))\n",
    "            imsave(\"./output/imgs/fakeA_\" + str(epoch) + \"_\" + str(i) + \".jpg\",\n",
    "                   ((fake_B_temp[0] + 1) * 127.5).astype(np.uint8))\n",
    "            imsave(\"./output/imgs/cycA_\" + str(epoch) + \"_\" + str(i) + \".jpg\",\n",
    "                   ((cyc_A_temp[0] + 1) * 127.5).astype(np.uint8))\n",
    "            imsave(\"./output/imgs/cycB_\" + str(epoch) + \"_\" + str(i) + \".jpg\",\n",
    "                   ((cyc_B_temp[0] + 1) * 127.5).astype(np.uint8))\n",
    "            imsave(\"./output/imgs/inputA_\" + str(epoch) + \"_\" + str(i) + \".jpg\",\n",
    "                   ((self.A_input[i][0] + 1) * 127.5).astype(np.uint8))\n",
    "            imsave(\"./output/imgs/inputB_\" + str(epoch) + \"_\" + str(i) + \".jpg\",\n",
    "                   ((self.B_input[i][0] + 1) * 127.5).astype(np.uint8))\n",
    "\n",
    "    def fake_image_pool(self, num_fakes, fake, fake_pool):\n",
    "        ''' This function saves the generated image to corresponding pool of images.\n",
    "        In starting. It keeps on feeling the pool till it is full and then randomly selects an\n",
    "        already stored image and replace it with new one.'''\n",
    "\n",
    "        if (num_fakes < pool_size):\n",
    "            fake_pool[num_fakes] = fake\n",
    "            return fake\n",
    "        else:\n",
    "            p = random.random()\n",
    "            if p > 0.5:\n",
    "                random_id = random.randint(0, pool_size - 1)\n",
    "                temp = fake_pool[random_id]\n",
    "                fake_pool[random_id] = fake\n",
    "                return temp\n",
    "            else:\n",
    "                return fake\n",
    "\n",
    "    def train(self):\n",
    "\n",
    "        ''' Training Function '''\n",
    "\n",
    "        # Load Dataset from the dataset folder\n",
    "        self.input_setup()\n",
    "\n",
    "        # Build the network\n",
    "        self.model_setup()\n",
    "\n",
    "        # Loss function calculations\n",
    "        self.loss_calc()\n",
    "\n",
    "        # Initializing the global variables\n",
    "        init = tf.global_variables_initializer()\n",
    "        init2 = tf.local_variables_initializer()\n",
    "        saver = tf.train.Saver()\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(init)\n",
    "            sess.run(init2)\n",
    "\n",
    "            # Read input to nd array\n",
    "            self.input_read(sess)\n",
    "\n",
    "            # Restore the model to run the model from last checkpoint\n",
    "            if to_restore:\n",
    "                chkpt_fname = tf.train.latest_checkpoint(check_dir)\n",
    "                saver.restore(sess, chkpt_fname)\n",
    "\n",
    "            writer = tf.summary.FileWriter(\"./output/2\")\n",
    "\n",
    "            if not os.path.exists(check_dir):\n",
    "                os.makedirs(check_dir)\n",
    "\n",
    "            # Training Loop\n",
    "            for epoch in range(sess.run(self.global_step), 10):\n",
    "                print(\"In the epoch \", epoch)\n",
    "                saver.save(sess, os.path.join(check_dir, \"cyclegan\"), global_step=epoch)\n",
    "\n",
    "                # Dealing with the learning rate as per the epoch number\n",
    "                if (epoch < 100):\n",
    "                    curr_lr = 0.0002\n",
    "                else:\n",
    "                    curr_lr = 0.0002 - 0.0002 * (epoch - 100) / 100\n",
    "\n",
    "                if (save_training_images):\n",
    "                    self.save_training_images(sess, epoch)\n",
    "\n",
    "                # sys.exit()\n",
    "\n",
    "                for ptr in range(0, max_images):\n",
    "                    print(\"In the iteration \", ptr)\n",
    "                    print(\"Starting\", time.time() * 1000.0)\n",
    "\n",
    "                    # Optimizing the G_A network\n",
    "\n",
    "                    _, fake_B_temp, summary_str = sess.run([self.g_A_trainer, self.fake_B, self.g_A_loss_summ],\n",
    "                                                           feed_dict={self.input_A: self.A_input[ptr],\n",
    "                                                                      self.input_B: self.B_input[ptr],\n",
    "                                                                      self.lr: curr_lr})\n",
    "\n",
    "                    writer.add_summary(summary_str, epoch * max_images + ptr)\n",
    "                    fake_B_temp1 = self.fake_image_pool(self.num_fake_inputs, fake_B_temp, self.fake_images_B)\n",
    "\n",
    "                    # Optimizing the D_B network\n",
    "                    _, summary_str = sess.run([self.d_B_trainer, self.d_B_loss_summ],\n",
    "                                              feed_dict={self.input_A: self.A_input[ptr],\n",
    "                                                         self.input_B: self.B_input[ptr], self.lr: curr_lr,\n",
    "                                                         self.fake_pool_B: fake_B_temp1})\n",
    "                    writer.add_summary(summary_str, epoch * max_images + ptr)\n",
    "\n",
    "                    # Optimizing the G_B network\n",
    "                    _, fake_A_temp, summary_str = sess.run([self.g_B_trainer, self.fake_A, self.g_B_loss_summ],\n",
    "                                                           feed_dict={self.input_A: self.A_input[ptr],\n",
    "                                                                      self.input_B: self.B_input[ptr],\n",
    "                                                                      self.lr: curr_lr})\n",
    "\n",
    "                    writer.add_summary(summary_str, epoch * max_images + ptr)\n",
    "\n",
    "                    fake_A_temp1 = self.fake_image_pool(self.num_fake_inputs, fake_A_temp, self.fake_images_A)\n",
    "\n",
    "                    # Optimizing the D_A network\n",
    "                    _, summary_str = sess.run([self.d_A_trainer, self.d_A_loss_summ],\n",
    "                                              feed_dict={self.input_A: self.A_input[ptr],\n",
    "                                                         self.input_B: self.B_input[ptr], self.lr: curr_lr,\n",
    "                                                         self.fake_pool_A: fake_A_temp1})\n",
    "\n",
    "                    writer.add_summary(summary_str, epoch * max_images + ptr)\n",
    "\n",
    "                    self.num_fake_inputs += 1\n",
    "\n",
    "                sess.run(tf.assign(self.global_step, epoch + 1))\n",
    "\n",
    "            writer.add_graph(sess.graph)\n",
    "\n",
    "    def test(self):\n",
    "\n",
    "        ''' Testing Function'''\n",
    "\n",
    "        print(\"Testing the results\")\n",
    "        tf.reset_default_graph()\n",
    "        self.input_setup()\n",
    "\n",
    "        self.model_setup()\n",
    "        saver = tf.train.Saver()\n",
    "        init = tf.global_variables_initializer()\n",
    "        init2 = tf.local_variables_initializer()\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "\n",
    "            sess.run(init)\n",
    "            sess.run(init2)\n",
    "\n",
    "            self.input_read(sess)\n",
    "\n",
    "            chkpt_fname = tf.train.latest_checkpoint(check_dir)\n",
    "            saver.restore(sess, chkpt_fname)\n",
    "\n",
    "            if not os.path.exists(\"./output/imgs/test/\"):\n",
    "                os.makedirs(\"./output/imgs/test/\")\n",
    "\n",
    "            for i in range(0, 100):\n",
    "                fake_A_temp, fake_B_temp = sess.run([self.fake_A, self.fake_B],\n",
    "                                                    feed_dict={self.input_A: self.A_input[i],\n",
    "                                                               self.input_B: self.B_input[i]})\n",
    "                imsave(\"./output/imgs/test/fakeB_\" + str(i) + \".jpg\", ((fake_A_temp[0] + 1) * 127.5).astype(np.uint8))\n",
    "                imsave(\"./output/imgs/test/fakeA_\" + str(i) + \".jpg\", ((fake_B_temp[0] + 1) * 127.5).astype(np.uint8))\n",
    "                imsave(\"./output/imgs/test/inputA_\" + str(i) + \".jpg\",\n",
    "                       ((self.A_input[i][0] + 1) * 127.5).astype(np.uint8))\n",
    "                imsave(\"./output/imgs/test/inputB_\" + str(i) + \".jpg\",\n",
    "                       ((self.B_input[i][0] + 1) * 127.5).astype(np.uint8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-2db27e51d563>:43: string_input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(string_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /Users/Apple/anaconda3/envs/deepL/lib/python3.6/site-packages/tensorflow/python/training/input.py:276: input_producer (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensor_slices(input_tensor).shuffle(tf.shape(input_tensor, out_type=tf.int64)[0]).repeat(num_epochs)`. If `shuffle=False`, omit the `.shuffle(...)`.\n",
      "WARNING:tensorflow:From /Users/Apple/anaconda3/envs/deepL/lib/python3.6/site-packages/tensorflow/python/training/input.py:188: limit_epochs (from tensorflow.python.training.input) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.from_tensors(tensor).repeat(num_epochs)`.\n",
      "WARNING:tensorflow:From /Users/Apple/anaconda3/envs/deepL/lib/python3.6/site-packages/tensorflow/python/training/input.py:197: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From /Users/Apple/anaconda3/envs/deepL/lib/python3.6/site-packages/tensorflow/python/training/input.py:197: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "WARNING:tensorflow:From <ipython-input-2-2db27e51d563>:46: WholeFileReader.__init__ (from tensorflow.python.ops.io_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Queue-based input pipelines have been replaced by `tf.data`. Use `tf.data.Dataset.map(tf.read_file)`.\n",
      "Model/g_A/c1/Conv/weights:0\n",
      "Model/g_A/c1/Conv/biases:0\n",
      "Model/g_A/c1/instance_norm/scale:0\n",
      "Model/g_A/c1/instance_norm/offset:0\n",
      "Model/g_A/c2/Conv/weights:0\n",
      "Model/g_A/c2/Conv/biases:0\n",
      "Model/g_A/c2/instance_norm/scale:0\n",
      "Model/g_A/c2/instance_norm/offset:0\n",
      "Model/g_A/c3/Conv/weights:0\n",
      "Model/g_A/c3/Conv/biases:0\n",
      "Model/g_A/c3/instance_norm/scale:0\n",
      "Model/g_A/c3/instance_norm/offset:0\n",
      "Model/g_A/r1/c1/Conv/weights:0\n",
      "Model/g_A/r1/c1/Conv/biases:0\n",
      "Model/g_A/r1/c1/instance_norm/scale:0\n",
      "Model/g_A/r1/c1/instance_norm/offset:0\n",
      "Model/g_A/r1/c2/Conv/weights:0\n",
      "Model/g_A/r1/c2/Conv/biases:0\n",
      "Model/g_A/r1/c2/instance_norm/scale:0\n",
      "Model/g_A/r1/c2/instance_norm/offset:0\n",
      "Model/g_A/r2/c1/Conv/weights:0\n",
      "Model/g_A/r2/c1/Conv/biases:0\n",
      "Model/g_A/r2/c1/instance_norm/scale:0\n",
      "Model/g_A/r2/c1/instance_norm/offset:0\n",
      "Model/g_A/r2/c2/Conv/weights:0\n",
      "Model/g_A/r2/c2/Conv/biases:0\n",
      "Model/g_A/r2/c2/instance_norm/scale:0\n",
      "Model/g_A/r2/c2/instance_norm/offset:0\n",
      "Model/g_A/r3/c1/Conv/weights:0\n",
      "Model/g_A/r3/c1/Conv/biases:0\n",
      "Model/g_A/r3/c1/instance_norm/scale:0\n",
      "Model/g_A/r3/c1/instance_norm/offset:0\n",
      "Model/g_A/r3/c2/Conv/weights:0\n",
      "Model/g_A/r3/c2/Conv/biases:0\n",
      "Model/g_A/r3/c2/instance_norm/scale:0\n",
      "Model/g_A/r3/c2/instance_norm/offset:0\n",
      "Model/g_A/r4/c1/Conv/weights:0\n",
      "Model/g_A/r4/c1/Conv/biases:0\n",
      "Model/g_A/r4/c1/instance_norm/scale:0\n",
      "Model/g_A/r4/c1/instance_norm/offset:0\n",
      "Model/g_A/r4/c2/Conv/weights:0\n",
      "Model/g_A/r4/c2/Conv/biases:0\n",
      "Model/g_A/r4/c2/instance_norm/scale:0\n",
      "Model/g_A/r4/c2/instance_norm/offset:0\n",
      "Model/g_A/r5/c1/Conv/weights:0\n",
      "Model/g_A/r5/c1/Conv/biases:0\n",
      "Model/g_A/r5/c1/instance_norm/scale:0\n",
      "Model/g_A/r5/c1/instance_norm/offset:0\n",
      "Model/g_A/r5/c2/Conv/weights:0\n",
      "Model/g_A/r5/c2/Conv/biases:0\n",
      "Model/g_A/r5/c2/instance_norm/scale:0\n",
      "Model/g_A/r5/c2/instance_norm/offset:0\n",
      "Model/g_A/r6/c1/Conv/weights:0\n",
      "Model/g_A/r6/c1/Conv/biases:0\n",
      "Model/g_A/r6/c1/instance_norm/scale:0\n",
      "Model/g_A/r6/c1/instance_norm/offset:0\n",
      "Model/g_A/r6/c2/Conv/weights:0\n",
      "Model/g_A/r6/c2/Conv/biases:0\n",
      "Model/g_A/r6/c2/instance_norm/scale:0\n",
      "Model/g_A/r6/c2/instance_norm/offset:0\n",
      "Model/g_A/r7/c1/Conv/weights:0\n",
      "Model/g_A/r7/c1/Conv/biases:0\n",
      "Model/g_A/r7/c1/instance_norm/scale:0\n",
      "Model/g_A/r7/c1/instance_norm/offset:0\n",
      "Model/g_A/r7/c2/Conv/weights:0\n",
      "Model/g_A/r7/c2/Conv/biases:0\n",
      "Model/g_A/r7/c2/instance_norm/scale:0\n",
      "Model/g_A/r7/c2/instance_norm/offset:0\n",
      "Model/g_A/r8/c1/Conv/weights:0\n",
      "Model/g_A/r8/c1/Conv/biases:0\n",
      "Model/g_A/r8/c1/instance_norm/scale:0\n",
      "Model/g_A/r8/c1/instance_norm/offset:0\n",
      "Model/g_A/r8/c2/Conv/weights:0\n",
      "Model/g_A/r8/c2/Conv/biases:0\n",
      "Model/g_A/r8/c2/instance_norm/scale:0\n",
      "Model/g_A/r8/c2/instance_norm/offset:0\n",
      "Model/g_A/r9/c1/Conv/weights:0\n",
      "Model/g_A/r9/c1/Conv/biases:0\n",
      "Model/g_A/r9/c1/instance_norm/scale:0\n",
      "Model/g_A/r9/c1/instance_norm/offset:0\n",
      "Model/g_A/r9/c2/Conv/weights:0\n",
      "Model/g_A/r9/c2/Conv/biases:0\n",
      "Model/g_A/r9/c2/instance_norm/scale:0\n",
      "Model/g_A/r9/c2/instance_norm/offset:0\n",
      "Model/g_A/c4/Conv2d_transpose/weights:0\n",
      "Model/g_A/c4/Conv2d_transpose/biases:0\n",
      "Model/g_A/c4/instance_norm/scale:0\n",
      "Model/g_A/c4/instance_norm/offset:0\n",
      "Model/g_A/c5/Conv2d_transpose/weights:0\n",
      "Model/g_A/c5/Conv2d_transpose/biases:0\n",
      "Model/g_A/c5/instance_norm/scale:0\n",
      "Model/g_A/c5/instance_norm/offset:0\n",
      "Model/g_A/c6/Conv/weights:0\n",
      "Model/g_A/c6/Conv/biases:0\n",
      "Model/g_A/c6/instance_norm/scale:0\n",
      "Model/g_A/c6/instance_norm/offset:0\n",
      "Model/g_B/c1/Conv/weights:0\n",
      "Model/g_B/c1/Conv/biases:0\n",
      "Model/g_B/c1/instance_norm/scale:0\n",
      "Model/g_B/c1/instance_norm/offset:0\n",
      "Model/g_B/c2/Conv/weights:0\n",
      "Model/g_B/c2/Conv/biases:0\n",
      "Model/g_B/c2/instance_norm/scale:0\n",
      "Model/g_B/c2/instance_norm/offset:0\n",
      "Model/g_B/c3/Conv/weights:0\n",
      "Model/g_B/c3/Conv/biases:0\n",
      "Model/g_B/c3/instance_norm/scale:0\n",
      "Model/g_B/c3/instance_norm/offset:0\n",
      "Model/g_B/r1/c1/Conv/weights:0\n",
      "Model/g_B/r1/c1/Conv/biases:0\n",
      "Model/g_B/r1/c1/instance_norm/scale:0\n",
      "Model/g_B/r1/c1/instance_norm/offset:0\n",
      "Model/g_B/r1/c2/Conv/weights:0\n",
      "Model/g_B/r1/c2/Conv/biases:0\n",
      "Model/g_B/r1/c2/instance_norm/scale:0\n",
      "Model/g_B/r1/c2/instance_norm/offset:0\n",
      "Model/g_B/r2/c1/Conv/weights:0\n",
      "Model/g_B/r2/c1/Conv/biases:0\n",
      "Model/g_B/r2/c1/instance_norm/scale:0\n",
      "Model/g_B/r2/c1/instance_norm/offset:0\n",
      "Model/g_B/r2/c2/Conv/weights:0\n",
      "Model/g_B/r2/c2/Conv/biases:0\n",
      "Model/g_B/r2/c2/instance_norm/scale:0\n",
      "Model/g_B/r2/c2/instance_norm/offset:0\n",
      "Model/g_B/r3/c1/Conv/weights:0\n",
      "Model/g_B/r3/c1/Conv/biases:0\n",
      "Model/g_B/r3/c1/instance_norm/scale:0\n",
      "Model/g_B/r3/c1/instance_norm/offset:0\n",
      "Model/g_B/r3/c2/Conv/weights:0\n",
      "Model/g_B/r3/c2/Conv/biases:0\n",
      "Model/g_B/r3/c2/instance_norm/scale:0\n",
      "Model/g_B/r3/c2/instance_norm/offset:0\n",
      "Model/g_B/r4/c1/Conv/weights:0\n",
      "Model/g_B/r4/c1/Conv/biases:0\n",
      "Model/g_B/r4/c1/instance_norm/scale:0\n",
      "Model/g_B/r4/c1/instance_norm/offset:0\n",
      "Model/g_B/r4/c2/Conv/weights:0\n",
      "Model/g_B/r4/c2/Conv/biases:0\n",
      "Model/g_B/r4/c2/instance_norm/scale:0\n",
      "Model/g_B/r4/c2/instance_norm/offset:0\n",
      "Model/g_B/r5/c1/Conv/weights:0\n",
      "Model/g_B/r5/c1/Conv/biases:0\n",
      "Model/g_B/r5/c1/instance_norm/scale:0\n",
      "Model/g_B/r5/c1/instance_norm/offset:0\n",
      "Model/g_B/r5/c2/Conv/weights:0\n",
      "Model/g_B/r5/c2/Conv/biases:0\n",
      "Model/g_B/r5/c2/instance_norm/scale:0\n",
      "Model/g_B/r5/c2/instance_norm/offset:0\n",
      "Model/g_B/r6/c1/Conv/weights:0\n",
      "Model/g_B/r6/c1/Conv/biases:0\n",
      "Model/g_B/r6/c1/instance_norm/scale:0\n",
      "Model/g_B/r6/c1/instance_norm/offset:0\n",
      "Model/g_B/r6/c2/Conv/weights:0\n",
      "Model/g_B/r6/c2/Conv/biases:0\n",
      "Model/g_B/r6/c2/instance_norm/scale:0\n",
      "Model/g_B/r6/c2/instance_norm/offset:0\n",
      "Model/g_B/r7/c1/Conv/weights:0\n",
      "Model/g_B/r7/c1/Conv/biases:0\n",
      "Model/g_B/r7/c1/instance_norm/scale:0\n",
      "Model/g_B/r7/c1/instance_norm/offset:0\n",
      "Model/g_B/r7/c2/Conv/weights:0\n",
      "Model/g_B/r7/c2/Conv/biases:0\n",
      "Model/g_B/r7/c2/instance_norm/scale:0\n",
      "Model/g_B/r7/c2/instance_norm/offset:0\n",
      "Model/g_B/r8/c1/Conv/weights:0\n",
      "Model/g_B/r8/c1/Conv/biases:0\n",
      "Model/g_B/r8/c1/instance_norm/scale:0\n",
      "Model/g_B/r8/c1/instance_norm/offset:0\n",
      "Model/g_B/r8/c2/Conv/weights:0\n",
      "Model/g_B/r8/c2/Conv/biases:0\n",
      "Model/g_B/r8/c2/instance_norm/scale:0\n",
      "Model/g_B/r8/c2/instance_norm/offset:0\n",
      "Model/g_B/r9/c1/Conv/weights:0\n",
      "Model/g_B/r9/c1/Conv/biases:0\n",
      "Model/g_B/r9/c1/instance_norm/scale:0\n",
      "Model/g_B/r9/c1/instance_norm/offset:0\n",
      "Model/g_B/r9/c2/Conv/weights:0\n",
      "Model/g_B/r9/c2/Conv/biases:0\n",
      "Model/g_B/r9/c2/instance_norm/scale:0\n",
      "Model/g_B/r9/c2/instance_norm/offset:0\n",
      "Model/g_B/c4/Conv2d_transpose/weights:0\n",
      "Model/g_B/c4/Conv2d_transpose/biases:0\n",
      "Model/g_B/c4/instance_norm/scale:0\n",
      "Model/g_B/c4/instance_norm/offset:0\n",
      "Model/g_B/c5/Conv2d_transpose/weights:0\n",
      "Model/g_B/c5/Conv2d_transpose/biases:0\n",
      "Model/g_B/c5/instance_norm/scale:0\n",
      "Model/g_B/c5/instance_norm/offset:0\n",
      "Model/g_B/c6/Conv/weights:0\n",
      "Model/g_B/c6/Conv/biases:0\n",
      "Model/g_B/c6/instance_norm/scale:0\n",
      "Model/g_B/c6/instance_norm/offset:0\n",
      "Model/d_A/c1/Conv/weights:0\n",
      "Model/d_A/c1/Conv/biases:0\n",
      "Model/d_A/c2/Conv/weights:0\n",
      "Model/d_A/c2/Conv/biases:0\n",
      "Model/d_A/c2/instance_norm/scale:0\n",
      "Model/d_A/c2/instance_norm/offset:0\n",
      "Model/d_A/c3/Conv/weights:0\n",
      "Model/d_A/c3/Conv/biases:0\n",
      "Model/d_A/c3/instance_norm/scale:0\n",
      "Model/d_A/c3/instance_norm/offset:0\n",
      "Model/d_A/c4/Conv/weights:0\n",
      "Model/d_A/c4/Conv/biases:0\n",
      "Model/d_A/c4/instance_norm/scale:0\n",
      "Model/d_A/c4/instance_norm/offset:0\n",
      "Model/d_A/c5/Conv/weights:0\n",
      "Model/d_A/c5/Conv/biases:0\n",
      "Model/d_B/c1/Conv/weights:0\n",
      "Model/d_B/c1/Conv/biases:0\n",
      "Model/d_B/c2/Conv/weights:0\n",
      "Model/d_B/c2/Conv/biases:0\n",
      "Model/d_B/c2/instance_norm/scale:0\n",
      "Model/d_B/c2/instance_norm/offset:0\n",
      "Model/d_B/c3/Conv/weights:0\n",
      "Model/d_B/c3/Conv/biases:0\n",
      "Model/d_B/c3/instance_norm/scale:0\n",
      "Model/d_B/c3/instance_norm/offset:0\n",
      "Model/d_B/c4/Conv/weights:0\n",
      "Model/d_B/c4/Conv/biases:0\n",
      "Model/d_B/c4/instance_norm/scale:0\n",
      "Model/d_B/c4/instance_norm/offset:0\n",
      "Model/d_B/c5/Conv/weights:0\n",
      "Model/d_B/c5/Conv/biases:0\n",
      "WARNING:tensorflow:From <ipython-input-2-2db27e51d563>:65: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "To construct input pipelines, use the `tf.data` module.\n",
      "In the epoch  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Apple/anaconda3/envs/deepL/lib/python3.6/site-packages/ipykernel_launcher.py:182: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "/Users/Apple/anaconda3/envs/deepL/lib/python3.6/site-packages/ipykernel_launcher.py:184: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "/Users/Apple/anaconda3/envs/deepL/lib/python3.6/site-packages/ipykernel_launcher.py:186: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "/Users/Apple/anaconda3/envs/deepL/lib/python3.6/site-packages/ipykernel_launcher.py:188: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "/Users/Apple/anaconda3/envs/deepL/lib/python3.6/site-packages/ipykernel_launcher.py:190: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n",
      "/Users/Apple/anaconda3/envs/deepL/lib/python3.6/site-packages/ipykernel_launcher.py:192: DeprecationWarning: `imsave` is deprecated!\n",
      "`imsave` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imwrite`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the iteration  0\n",
      "Starting 1555093042505.124\n",
      "In the iteration  1\n",
      "Starting 1555093127547.057\n",
      "In the iteration  2\n",
      "Starting 1555093155419.717\n",
      "In the iteration  3\n",
      "Starting 1555093182949.6719\n",
      "In the iteration  4\n",
      "Starting 1555093210549.386\n",
      "In the iteration  5\n",
      "Starting 1555093237489.982\n",
      "In the iteration  6\n",
      "Starting 1555093264344.738\n",
      "In the iteration  7\n",
      "Starting 1555093289557.539\n",
      "In the iteration  8\n",
      "Starting 1555093316001.6538\n",
      "In the iteration  9\n",
      "Starting 1555093345375.837\n",
      "In the iteration  10\n",
      "Starting 1555093379312.654\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d086738e635f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-d086738e635f>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCycleGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-2db27e51d563>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    270\u001b[0m                                                            feed_dict={self.input_A: self.A_input[ptr],\n\u001b[1;32m    271\u001b[0m                                                                       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_B\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mB_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mptr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m                                                                       self.lr: curr_lr})\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                     \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmax_images\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepL/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepL/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepL/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepL/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepL/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/deepL/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    model = CycleGAN()\n",
    "    model.train()\n",
    "    model.test()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
