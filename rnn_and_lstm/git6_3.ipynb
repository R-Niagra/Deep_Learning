{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ya1dJNI03vUG"
   },
   "source": [
    "Since there is basically no external data file, this notebook is extremly simple to open in collab and to train your models there. This is highly recommended since LSTMS take longer to train. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1851,
     "status": "ok",
     "timestamp": 1556572077963,
     "user": {
      "displayName": "Rizwan Shahid",
      "photoUrl": "",
      "userId": "01725751252782526873"
     },
     "user_tz": -300
    },
    "id": "1qOa41PD6p2T",
    "outputId": "4ba96e1f-4d61-4a10-fac2-a3b10a727738"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BPKdISeNb6Ny"
   },
   "source": [
    "# **Task 3: **\n",
    "\n",
    "**We're going to build a network that takes and converts dates from one format into another. **\n",
    "\n",
    "For example, given a date string such as \"14-03-2020\", we want out network to, character by character read this string and output to us \"The 14th of March 2020\".\n",
    "\n",
    "Since our data is a sequence of information, each part derives it's meaning from a prior part.\n",
    "\"2\" as the second month character could either encode for Feb or for december depending on what number preceded it. This is a problem that is well handled by recurrent neural networks. \n",
    "\n",
    "We're going to be using LSTM's to build this network, which are recurrent learning cells. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i2Dn8er7fEzJ"
   },
   "source": [
    "Below is a model that allows us to do sequence to sequence conversion where the input and output are of different lengths, the example provided is one of english to french translation. This is similar to the encoder, decoder style of machine translation we have learnt about in class.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SFPZi1gi1lUy"
   },
   "source": [
    "![alt text](https://blog.keras.io/img/seq2seq/seq2seq-teacher-forcing.png)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-NaVnqtr1xLO"
   },
   "source": [
    "Below is a function that generates the dataset, giving you date entries in different formats in for as many days (2019 April 15th onwards) as you'd like.\n",
    "Go ahead, test it, see how it returns values and what they are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pvDoWosatnoC"
   },
   "source": [
    "### Make Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-GIMoCVttnoF"
   },
   "outputs": [],
   "source": [
    "def make_short_date(dt):\n",
    "    return dt.strftime('%d-%m-%Y')\n",
    "\n",
    "def make_long_date(dt):\n",
    "    date = dt.strftime('%d')\n",
    "    if date[-1] == '1':\n",
    "        suffix = 'st'\n",
    "    elif date[-1] == '2':\n",
    "        suffix = 'nd'\n",
    "    elif date[-1] == '3':\n",
    "        suffix = 'rd'\n",
    "    else:\n",
    "        suffix = 'th'\n",
    "    month = dt.strftime('%B')\n",
    "    year = dt.strftime('%Y')\n",
    "    \n",
    "    return date + suffix + ' of ' + month + ' ' + year\n",
    "\n",
    "def make_dataset(n):\n",
    "    dates = pd.date_range(datetime(1990, 4, 14), periods=n, normalize=True)\n",
    "    \n",
    "    x = dates.map(make_short_date).values\n",
    "    y = dates.map(make_long_date).values\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1017,
     "status": "ok",
     "timestamp": 1556572083061,
     "user": {
      "displayName": "Rizwan Shahid",
      "photoUrl": "",
      "userId": "01725751252782526873"
     },
     "user_tz": -300
    },
    "id": "euanX1Mctnog",
    "outputId": "0d060235-74ae-4531-d557-e2fc3d5a95fe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['14-04-1990', '15-04-1990', '16-04-1990', '17-04-1990',\n",
       "        '18-04-1990'], dtype=object),\n",
       " array(['14th of April 1990', '15th of April 1990', '16th of April 1990',\n",
       "        '17th of April 1990', '18th of April 1990'], dtype=object))"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = make_dataset(50)\n",
    "x[:5], y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J_H6BdzZfo-l"
   },
   "source": [
    "We've got some hyper-paramters set for you here, we're going to start working with 10,000 training examples and see how well our models trains with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R1h84iik-FXh"
   },
   "outputs": [],
   "source": [
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 100  # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "num_samples = 10000  # Number of samples to train on.\n",
    "# Path to the data txt file on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1534,
     "status": "ok",
     "timestamp": 1556572084088,
     "user": {
      "displayName": "Rizwan Shahid",
      "photoUrl": "",
      "userId": "01725751252782526873"
     },
     "user_tz": -300
    },
    "id": "MbTUAyfmtno2",
    "outputId": "82524d68-1265-4709-82ee-e438bd2056a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14th of April 1990\n"
     ]
    }
   ],
   "source": [
    "dataset = make_dataset(num_samples)\n",
    "print(dataset[1][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hKruNCkNfzjw"
   },
   "source": [
    "### Part 1 - Generation and preperation of dataset\n",
    "\n",
    "Prepare the dataset for training. The following steps will have to be taken.\n",
    "\n",
    "We need a total of 3 datasets: \n",
    "1. encoder_input (our original data)\n",
    "2. decoder_input (the target data with start and end tokens added) -> our start token is a \"\\t\" character, and the stop character \"\\n\".\n",
    "3. decoder_target (target data without a start token, but with an end token) \n",
    "\n",
    "decoder_input and decoder_target data are different since once the model is trained, we will pass the decoder a sequence containing only a \"\\t\" and it will generate the rest of the sentence for us after, ending with the \"\\n\" token.\n",
    "\n",
    "Here is an example of this format of data for a single sample.\n",
    "\n",
    "encoder_input: \"14-03-2019\"\n",
    "decoder_input: \"\\tThe 14th of March 2019\\n\"\n",
    "decoder_target: \"The 14th of March 2019\\n\"\n",
    "\n",
    "Now that we know what the target is for the dataset, it's time to start converting it into a form the network can understand and work with.\n",
    "We need each sample to be an n*m numpy array of 0's. Where n is the maximum length of the sequence and m is the vocubulary size.\n",
    "\n",
    "An input would go from \"14-05-19\" to a array of size (1*8*10), where 1 is our batch size, 8 is sequence length and our vocab is 10 (including the '-').\n",
    "\n",
    "To do this, complete the following:\n",
    "\n",
    "1. Create a list of all possible vocab for the input and output target data (use a set)\n",
    "2. Use this set to create a dictionary that can convert characters into ints\n",
    "\n",
    "    *For instance you'll have a 'char_2_index' array that will function as \"char_2_index['-'] = 13\"*\n",
    "3. Convert these lists of ints into a 2d numpy array (3d when considering batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1683
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1720,
     "status": "ok",
     "timestamp": 1556572084595,
     "user": {
      "displayName": "Rizwan Shahid",
      "photoUrl": "",
      "userId": "01725751252782526873"
     },
     "user_tz": -300
    },
    "id": "KY5_m9K96p2p",
    "outputId": "f36c8b57-7ae5-4103-c85d-f1d6fc0324df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 1.]\n",
      "  [0. 0. 0. ... 0. 0. 1.]\n",
      "  [0. 1. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 1.]\n",
      "  [0. 0. 0. ... 0. 0. 1.]\n",
      "  [0. 1. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 1.]\n",
      "  [0. 0. 0. ... 0. 0. 1.]\n",
      "  [0. 1. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 1. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 1. 0.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 1. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 1.]\n",
      "  [1. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 1. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 1. 0. 0.]]]\n",
      "[[[0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 1. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  ...\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]\n",
      "  [0. 0. 0. ... 0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "inp_list=['-','0','1','2','3','4','5','6','7','8','9']\n",
    "out_list=['\\t','\\n',]\n",
    "inpDict={}\n",
    "outDict={'-': 0, '0': 1, '1': 2, '2': 3, '3': 4, '4': 5, '5': 6, '6': 7, '7': 8, '8': 9, '9': 10}\n",
    "date_len=10\n",
    "max_output_len=27\n",
    "\n",
    "count=11\n",
    "input_shape=(date_len,len(inp_list))     #8 represents the length of the date string\n",
    "output_shape=(max_output_len,41)\n",
    "dec_inp_shape=(max_output_len,41)\n",
    "\n",
    "def populate_outlist(data):\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(data[i])):\n",
    "            if(data[i][j] not in out_list):\n",
    "                out_list.append(data[i][j])\n",
    "\n",
    "def char2array(data):\n",
    "    last_index=0\n",
    "    enc_I_array=np.zeros((len(data[0]), *input_shape))\n",
    "    \n",
    "    for i in range(len(data[0])):        \n",
    "        date_array=np.zeros((*input_shape,))\n",
    "        for k in range(date_len):\n",
    "            index=inpDict[data[0][i][k]]\n",
    "            date_array[k][index]=1\n",
    "\n",
    "        enc_I_array[i]=date_array\n",
    "    \n",
    "    dec_out_array=np.zeros((len(data[1]), *output_shape))       #decoded output array\n",
    "    dec_inp_array=np.zeros((len(data[1]), *dec_inp_shape))\n",
    "    \n",
    "    for i in range(len(data[1])):        \n",
    "        date_array=np.zeros((*output_shape,))\n",
    "        dec_array=np.zeros((*dec_inp_shape,))\n",
    "        dec_array[0][outDict['\\t']]=1\n",
    "        for j in range(len(data[1][i])):\n",
    "            index=outDict[data[1][i][j]]\n",
    "            date_array[j][index]=1\n",
    "            dec_array[j+1][index]=1\n",
    "\n",
    "        dec_out_array[i]=date_array\n",
    "        dec_inp_array[i]=dec_array\n",
    "        \n",
    "    \n",
    "    return enc_I_array,dec_inp_array,dec_out_array\n",
    "\n",
    "\n",
    "populate_outlist(dataset[1])\n",
    "# print(len(out_list))\n",
    "for i in range(len(inp_list)):      #Populate my_dict\n",
    "    inpDict[inp_list[i]]=i\n",
    "\n",
    "# print(inpDict)\n",
    "    \n",
    "for j in range(len(out_list)):\n",
    "    if(out_list[j] not in outDict):\n",
    "        outDict[out_list[j]]=count\n",
    "        count+=1;\n",
    "\n",
    "# print(inpDict)\n",
    "# print(outDict)\n",
    "\n",
    "enc_inp,dec_inp,dec_output=char2array(dataset)\n",
    "\n",
    "print(enc_inp)\n",
    "print(dec_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j_Vr_NaRy1tR"
   },
   "source": [
    "**Example: **\n",
    "\n",
    "Input sentence: 14-04-2019 into a 3d tensor would result in the following:\n",
    "\n",
    "\n",
    "[[[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    "\n",
    "  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
    "  \n",
    "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    "  \n",
    "  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    "  \n",
    "  [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
    "  \n",
    "  [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    "  \n",
    "  [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
    "  \n",
    "  [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    "  \n",
    "  [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
    "  \n",
    "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]]\n",
    "-\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H4oTdGIqhCs1"
   },
   "source": [
    "**Part 2 - Setting up the network**\n",
    "\n",
    "Before we begin, uncomment the following lines of code and fill in appropriate variables to have an overview of what your network will be training with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1220,
     "status": "ok",
     "timestamp": 1556572084596,
     "user": {
      "displayName": "Rizwan Shahid",
      "photoUrl": "",
      "userId": "01725751252782526873"
     },
     "user_tz": -300
    },
    "id": "dsFIgc7WtnpB",
    "outputId": "017bae5d-77c3-422a-8304-c7cf109f012e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 10000\n",
      "Number of unique input tokens: 11\n",
      "Number of unique output tokens: 41\n",
      "Max sequence length for inputs: 10\n",
      "Max sequence length for outputs: 27\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples:', len(enc_inp))\n",
    "print('Number of unique input tokens:', len(inpDict))\n",
    "print('Number of unique output tokens:', len(outDict))\n",
    "print('Max sequence length for inputs:', date_len)\n",
    "print('Max sequence length for outputs:', max_output_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QtoKiL3mjdOt"
   },
   "source": [
    "Great, now you have to set up an encoder decoder network. \n",
    "\n",
    "This will require 2 LSTMS\n",
    "\n",
    "1. An encoder LSTM (size - latent dimension as we defined above):\n",
    "  - We'll pass our encoder_input data to this\n",
    "  - We will let it run through the LSTM and get the states back from it (discard the network output, we only need the c and h states), save these\n",
    " \n",
    "2. A decoder LSTM (size - latent dimension):\n",
    "  - We'll be passing decoder_input data to this (with the '\\t' and ''\\n' added and encoded)\n",
    "  - We will also be passing a specific initial state to this (states c and h, taken from the encoder network)\n",
    "  \n",
    "Following this LSTM, you will need a dense layer of output_tokens (output vocab) size to convert the result into a one hot encoded target. Figure out what activation this should require"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1174,
     "status": "ok",
     "timestamp": 1556572084978,
     "user": {
      "displayName": "Rizwan Shahid",
      "photoUrl": "",
      "userId": "01725751252782526873"
     },
     "user_tz": -300
    },
    "id": "824bTKHE4BdG",
    "outputId": "07345d38-4210-4c03-b5b9-61ebc284bc9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = Input(shape=(None, len(inpDict)))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YQWudG_D4BbO"
   },
   "outputs": [],
   "source": [
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, len(outDict)))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the \n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(len(outDict), activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_IHxijrP4BZY"
   },
   "outputs": [],
   "source": [
    " #Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 973
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5584657,
     "status": "error",
     "timestamp": 1556577672004,
     "user": {
      "displayName": "Rizwan Shahid",
      "photoUrl": "",
      "userId": "01725751252782526873"
     },
     "user_tz": -300
    },
    "id": "xqyyGvtT4BX3",
    "outputId": "6983db89-662c-4e69-93ab-ef8bec3af79e"
   },
   "outputs": [],
   "source": [
    "# Run training\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.fit([enc_inp,dec_inp],dec_output,batch_size=1,epochs=20,validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2eFKrSlO0_VM"
   },
   "source": [
    "** Model structure ** \n",
    "\n",
    "So you have \n",
    "\n",
    "  1. (encoder_input) -> encoder LSTM -> (output, states)\n",
    "  2. (decoder_input, states) -> decoder LSTM -> Dense (decoder_output)\n",
    "  \n",
    "For the overall model: \n",
    "1. Inputs - [encoder_input, decoder_input]\n",
    "2. Outputs - [decoder_target]\n",
    "\n",
    "Model Optimizer - RMSProp\n",
    "Model Loss - categorical_crossentropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J4KCRh_Z4ClD"
   },
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lRkU-IxSQx6J"
   },
   "outputs": [],
   "source": [
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in inpDict.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in outDict.items())\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, len(outDict)))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, outDict['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n'):\n",
    "            print(\"came in stop condition\")\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_output_len):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, len(outDict)))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 5117
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3768,
     "status": "ok",
     "timestamp": 1556580169191,
     "user": {
      "displayName": "Rizwan Shahid",
      "photoUrl": "",
      "userId": "01725751252782526873"
     },
     "user_tz": -300
    },
    "id": "7Qf9Lu9lQ37b",
    "outputId": "f2fdc68a-4391-41ce-f185-fe380f85252d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Input sentence: 14-04-1990\n",
      "Decoded sentence: 14th of April 19900820ec2000\n",
      "-\n",
      "Input sentence: 15-04-1990\n",
      "Decoded sentence: 15th of April 19900820ec2000\n",
      "-\n",
      "Input sentence: 16-04-1990\n",
      "Decoded sentence: 16th of April 19900820ec2000\n",
      "-\n",
      "Input sentence: 17-04-1990\n",
      "Decoded sentence: 17th of April 19900820ec2000\n",
      "-\n",
      "Input sentence: 18-04-1990\n",
      "Decoded sentence: 18th of April 19900820ec2000\n",
      "-\n",
      "Input sentence: 19-04-1990\n",
      "Decoded sentence: 19th of April 19900820ecembe\n",
      "-\n",
      "Input sentence: 20-04-1990\n",
      "Decoded sentence: 20th of April 19900820ec2000\n",
      "-\n",
      "Input sentence: 21-04-1990\n",
      "Decoded sentence: 21th of April 19900820ec2000\n",
      "-\n",
      "Input sentence: 22-04-1990\n",
      "Decoded sentence: 22th of April 19900820ec2000\n",
      "-\n",
      "Input sentence: 23-04-1990\n",
      "Decoded sentence: 23th of April 19900820ecembe\n",
      "-\n",
      "Input sentence: 24-04-1990\n",
      "Decoded sentence: 24th of April 19900820ec2000\n",
      "-\n",
      "Input sentence: 25-04-1990\n",
      "Decoded sentence: 25th of April 19900820ec2000\n",
      "-\n",
      "Input sentence: 26-04-1990\n",
      "Decoded sentence: 26th of April 19900820ec2000\n",
      "-\n",
      "Input sentence: 27-04-1990\n",
      "Decoded sentence: 27th of April 19900820ec2000\n",
      "-\n",
      "Input sentence: 28-04-1990\n",
      "Decoded sentence: 28th of April 19900820ec2000\n",
      "-\n",
      "Input sentence: 29-04-1990\n",
      "Decoded sentence: 29th of April 19900820ecembe\n",
      "-\n",
      "Input sentence: 30-04-1990\n",
      "Decoded sentence: 30th of April 19900820ec2000\n",
      "-\n",
      "Input sentence: 01-05-1990\n",
      "Decoded sentence: 01th of May 1990082nember 20\n",
      "-\n",
      "Input sentence: 02-05-1990\n",
      "Decoded sentence: 02th of May 1990082nember 20\n",
      "-\n",
      "Input sentence: 03-05-1990\n",
      "Decoded sentence: 03th of May 1990082nember 20\n",
      "-\n",
      "Input sentence: 04-05-1990\n",
      "Decoded sentence: 04th of May 1990082nember 20\n",
      "-\n",
      "Input sentence: 05-05-1990\n",
      "Decoded sentence: 05th of May 1990082nember 20\n",
      "-\n",
      "Input sentence: 06-05-1990\n",
      "Decoded sentence: 06th of May 1990082nember 20\n",
      "-\n",
      "Input sentence: 07-05-1990\n",
      "Decoded sentence: 07th of May 1990082nember 20\n",
      "-\n",
      "Input sentence: 08-05-1990\n",
      "Decoded sentence: 08th of May 1990082nember 20\n",
      "-\n",
      "Input sentence: 09-05-1990\n",
      "Decoded sentence: 09th of May 1990082nember 20\n",
      "-\n",
      "Input sentence: 10-05-1990\n",
      "Decoded sentence: 10th of May 1990082nember 20\n",
      "-\n",
      "Input sentence: 11-05-1990\n",
      "Decoded sentence: 11th of May 1990082nember 20\n",
      "-\n",
      "Input sentence: 12-05-1990\n",
      "Decoded sentence: 12th of May 1990082nember 20\n",
      "-\n",
      "Input sentence: 13-05-1990\n",
      "Decoded sentence: 13th of May 1990082nember 20\n",
      "-\n",
      "Input sentence: 14-05-1990\n",
      "Decoded sentence: 14th of May 1990082nember 20\n",
      "-\n",
      "Input sentence: 15-05-1990\n",
      "Decoded sentence: 15th of May 1990082nember 20\n",
      "-\n",
      "Input sentence: 16-05-1990\n",
      "Decoded sentence: 16th of May 1990082nember 20\n",
      "-\n",
      "Input sentence: 17-05-1990\n",
      "Decoded sentence: 17th of May 1990082nember 20\n",
      "-\n",
      "Input sentence: 18-05-1990\n",
      "Decoded sentence: 18th of May 1990082nember 20\n",
      "-\n",
      "Input sentence: 19-05-1990\n",
      "Decoded sentence: 19th of May 1990082nember 20\n",
      "-\n",
      "Input sentence: 20-05-1990\n",
      "Decoded sentence: 20th of May 1990082nember 20\n",
      "-\n",
      "Input sentence: 21-05-1990\n",
      "Decoded sentence: 21th of May 1990082nember 20\n",
      "-\n",
      "Input sentence: 22-05-1990\n",
      "Decoded sentence: 22th of May 1990082nember 20\n",
      "-\n",
      "Input sentence: 23-05-1990\n",
      "Decoded sentence: 23th of May 1990082nember 20\n",
      "-\n",
      "Input sentence: 24-05-1990\n",
      "Decoded sentence: 24th of May 1990082nember 20\n",
      "-\n",
      "Input sentence: 25-05-1990\n",
      "Decoded sentence: 25th of May 1990082nember 20\n",
      "-\n",
      "Input sentence: 26-05-1990\n",
      "Decoded sentence: 26th of May 1990082nember 20\n",
      "-\n",
      "Input sentence: 27-05-1990\n",
      "Decoded sentence: 27th of May 1990082nember 20\n",
      "-\n",
      "Input sentence: 28-05-1990\n",
      "Decoded sentence: 28th of May 1990082nember 20\n",
      "-\n",
      "Input sentence: 29-05-1990\n",
      "Decoded sentence: 29th of May 1990082nember 20\n",
      "-\n",
      "Input sentence: 30-05-1990\n",
      "Decoded sentence: 30th of May 1990082nember 20\n",
      "-\n",
      "Input sentence: 31-05-1990\n",
      "Decoded sentence: 31th of May 1990082nember 20\n",
      "-\n",
      "Input sentence: 01-06-1990\n",
      "Decoded sentence: 01th of June 199008nember 20\n",
      "-\n",
      "Input sentence: 02-06-1990\n",
      "Decoded sentence: 02th of June 199008nember 20\n",
      "-\n",
      "Input sentence: 03-06-1990\n",
      "Decoded sentence: 03th of June 199008nember 20\n",
      "-\n",
      "Input sentence: 04-06-1990\n",
      "Decoded sentence: 04th of June 1990082nec 2002\n",
      "-\n",
      "Input sentence: 05-06-1990\n",
      "Decoded sentence: 05th of June 1990082nec 2002\n",
      "-\n",
      "Input sentence: 06-06-1990\n",
      "Decoded sentence: 06th of June 1990082nember 2\n",
      "-\n",
      "Input sentence: 07-06-1990\n",
      "Decoded sentence: 07th of June 199008nember 20\n",
      "-\n",
      "Input sentence: 08-06-1990\n",
      "Decoded sentence: 08th of June 1990082nember 2\n",
      "-\n",
      "Input sentence: 09-06-1990\n",
      "Decoded sentence: 09th of June 199008nember 20\n",
      "-\n",
      "Input sentence: 10-06-1990\n",
      "Decoded sentence: 10th of June 199008nember 20\n",
      "-\n",
      "Input sentence: 11-06-1990\n",
      "Decoded sentence: 11th of June 199008nember 20\n",
      "-\n",
      "Input sentence: 12-06-1990\n",
      "Decoded sentence: 12th of June 199008nember 20\n",
      "-\n",
      "Input sentence: 13-06-1990\n",
      "Decoded sentence: 13th of June 199008nember 20\n",
      "-\n",
      "Input sentence: 14-06-1990\n",
      "Decoded sentence: 14th of June 1990082nember 2\n",
      "-\n",
      "Input sentence: 15-06-1990\n",
      "Decoded sentence: 15th of June 1990082nember 2\n",
      "-\n",
      "Input sentence: 16-06-1990\n",
      "Decoded sentence: 16th of June 1990082nember 2\n",
      "-\n",
      "Input sentence: 17-06-1990\n",
      "Decoded sentence: 17th of June 199008nember 20\n",
      "-\n",
      "Input sentence: 18-06-1990\n",
      "Decoded sentence: 18th of June 199008nember 20\n",
      "-\n",
      "Input sentence: 19-06-1990\n",
      "Decoded sentence: 19th of June 199008nember 20\n",
      "-\n",
      "Input sentence: 20-06-1990\n",
      "Decoded sentence: 20th of June 199008nember 20\n",
      "-\n",
      "Input sentence: 21-06-1990\n",
      "Decoded sentence: 21th of June 199008nember 20\n",
      "-\n",
      "Input sentence: 22-06-1990\n",
      "Decoded sentence: 22th of June 199008nember 20\n",
      "-\n",
      "Input sentence: 23-06-1990\n",
      "Decoded sentence: 23th of June 199008nember 20\n",
      "-\n",
      "Input sentence: 24-06-1990\n",
      "Decoded sentence: 24th of June 1990082nember 2\n",
      "-\n",
      "Input sentence: 25-06-1990\n",
      "Decoded sentence: 25th of June 199008nember 20\n",
      "-\n",
      "Input sentence: 26-06-1990\n",
      "Decoded sentence: 26th of June 1990082nember 2\n",
      "-\n",
      "Input sentence: 27-06-1990\n",
      "Decoded sentence: 27th of June 199008nember 20\n",
      "-\n",
      "Input sentence: 28-06-1990\n",
      "Decoded sentence: 28th of June 199008nember 20\n",
      "-\n",
      "Input sentence: 29-06-1990\n",
      "Decoded sentence: 29th of June 199008nember 20\n",
      "-\n",
      "Input sentence: 30-06-1990\n",
      "Decoded sentence: 30th of June 199008nember 20\n",
      "-\n",
      "Input sentence: 01-07-1990\n",
      "Decoded sentence: 01th of July 19900 20ecember\n",
      "-\n",
      "Input sentence: 02-07-1990\n",
      "Decoded sentence: 02th of July 19900 20ecember\n",
      "-\n",
      "Input sentence: 03-07-1990\n",
      "Decoded sentence: 03th of July 199008nember 20\n",
      "-\n",
      "Input sentence: 04-07-1990\n",
      "Decoded sentence: 04th of July 199008nember 20\n",
      "-\n",
      "Input sentence: 05-07-1990\n",
      "Decoded sentence: 05th of July 199008nember 20\n",
      "-\n",
      "Input sentence: 06-07-1990\n",
      "Decoded sentence: 06th of July 199008nember 20\n",
      "-\n",
      "Input sentence: 07-07-1990\n",
      "Decoded sentence: 07th of July 199008nember 20\n",
      "-\n",
      "Input sentence: 08-07-1990\n",
      "Decoded sentence: 08th of July 199008nember 20\n",
      "-\n",
      "Input sentence: 09-07-1990\n",
      "Decoded sentence: 09th of July 199008nember 20\n",
      "-\n",
      "Input sentence: 10-07-1990\n",
      "Decoded sentence: 10th of July 19900 20ecember\n",
      "-\n",
      "Input sentence: 11-07-1990\n",
      "Decoded sentence: 11th of July 19900 20ecember\n",
      "-\n",
      "Input sentence: 12-07-1990\n",
      "Decoded sentence: 12th of July 19900 20ecember\n",
      "-\n",
      "Input sentence: 13-07-1990\n",
      "Decoded sentence: 13th of July 19900 20ecember\n",
      "-\n",
      "Input sentence: 14-07-1990\n",
      "Decoded sentence: 14th of July 19900 20ecember\n",
      "-\n",
      "Input sentence: 15-07-1990\n",
      "Decoded sentence: 15th of July 19900 20ecember\n",
      "-\n",
      "Input sentence: 16-07-1990\n",
      "Decoded sentence: 16th of July 199008nember 20\n",
      "-\n",
      "Input sentence: 17-07-1990\n",
      "Decoded sentence: 17th of July 19900 20ecember\n",
      "-\n",
      "Input sentence: 18-07-1990\n",
      "Decoded sentence: 18th of July 19900 20ecember\n",
      "-\n",
      "Input sentence: 19-07-1990\n",
      "Decoded sentence: 19th of July 19900 20ecember\n",
      "-\n",
      "Input sentence: 20-07-1990\n",
      "Decoded sentence: 20th of July 19900 20ecember\n",
      "-\n",
      "Input sentence: 21-07-1990\n",
      "Decoded sentence: 21th of July 199008nember 20\n",
      "-\n",
      "Input sentence: 22-07-1990\n",
      "Decoded sentence: 22th of July 19900 20ecember\n"
     ]
    }
   ],
   "source": [
    "for seq_index in range(100):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = enc_inp[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', dataset[0][seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dRe_NYN33DIF"
   },
   "source": [
    "** Generating results **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1P8rBjbY2N08"
   },
   "source": [
    "Now that you've trained the network, you need to create two smaller subnetworks so that you can use them indepedantly for predictions:\n",
    "\n",
    "1. An encoder model to give you (encoder_input) -> (model states)\n",
    "2. a decoder model to give you (model_states + start_token) -> (next character)\n",
    "\n",
    "You will have to use these as following: \n",
    "\n",
    "  1. encode input and retrieve initial decoder state\n",
    "  \n",
    "  2. run one step of decoder with this initial state and a \"start of sequence\" token as target.\n",
    "  \n",
    "  Output will be the next target token\n",
    "  \n",
    "  3. Repeat with the current target token and current states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x6GdM2mX3PPS"
   },
   "source": [
    "The following illustration should help solidify this prediction loop better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "O7WdkUGt3B66"
   },
   "source": [
    "\n",
    "\n",
    "![alt text](https://blog.keras.io/img/seq2seq/seq2seq-inference.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MYyZCjfH4D-r"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UWuykLrK3VSc"
   },
   "source": [
    "** Part 3 - Improving result ** \n",
    "\n",
    "Now that you've got a working model, answer the following questions. \n",
    "\n",
    "1. What does the model return for a date from 1987? Why?\n",
    "2. What about a date from 2034?\n",
    "3. Now try the same date but in year 2134, what does the model return? Why is this so?\n",
    "4. How do we fix this problem?\n",
    "\n",
    "\n",
    "Answers:\n",
    "\n",
    "1. The model gives the correct result. It gives the correct translation\n",
    "2. No it can't translate sice it has not seen this in training.\n",
    "3. Same-> Can't predict the year. \n",
    "4. Just add the data in training model so that the model can assign weight to it. Otherwise it will be zero.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D58EBaw24MKK"
   },
   "outputs": [],
   "source": [
    "# improve the 'generate dataset' function to overcome the limitations you've highlighted in the previous part, use your answer to (4) for this\n",
    "# code this function below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AJXiJ7x-4Vdn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TM8bOo4d4Vam"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BnoyHGq84JZc"
   },
   "source": [
    "What did you change in this new version of the function?\n",
    "\n",
    "How will it help improve model results for the specific data points we mentioned earlier that our model had trouble with?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y9-9z1FZ4lYE"
   },
   "outputs": [],
   "source": [
    "# Demonstrate the improvement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12535,
     "status": "ok",
     "timestamp": 1556583203639,
     "user": {
      "displayName": "Rizwan Shahid",
      "photoUrl": "",
      "userId": "01725751252782526873"
     },
     "user_tz": -300
    },
    "id": "_HzUhIb9loml",
    "outputId": "01c4eca0-0ab9-46e3-fe6a-ce32dd53e598"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy==1.16.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/bf/4981bcbee43934f0adb8f764a1e70ab0ee5a448f6505bd04a87a2fda2a8b/numpy-1.16.1-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n",
      "\u001b[K     |████████████████████████████████| 17.3MB 3.4MB/s \n",
      "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.8 which is incompatible.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Found existing installation: numpy 1.16.3\n",
      "    Uninstalling numpy-1.16.3:\n",
      "      Successfully uninstalled numpy-1.16.3\n",
      "Successfully installed numpy-1.16.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "numpy"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install numpy==1.16.1\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 786
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 66177,
     "status": "error",
     "timestamp": 1556583293073,
     "user": {
      "displayName": "Rizwan Shahid",
      "photoUrl": "",
      "userId": "01725751252782526873"
     },
     "user_tz": -300
    },
    "id": "iF8dMUJplK7P",
    "outputId": "485363d9-c08e-4847-c8ee-497ecd816675"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 213,301\n",
      "Trainable params: 213,301\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/3\n",
      " 3264/25000 [==>...........................] - ETA: 5:59 - loss: 0.6791 - acc: 0.5680"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a9aa02f045be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;31m# Final evaluation of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# LSTM for sequence classification in the IMDB dataset\n",
    "import numpy\n",
    "from keras.datasets import imdb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load the dataset but only keep the top n words, zero the rest\n",
    "top_words = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)\n",
    "# truncate and pad input sequences\n",
    "max_review_length = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_review_length)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_review_length)\n",
    "# create the model\n",
    "embedding_vecor_length = 32\n",
    "model = Sequential()\n",
    "model.add(Embedding(top_words, embedding_vecor_length, input_length=max_review_length))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(X_train, y_train, epochs=3, batch_size=64)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZpEVTi_jlTAx"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Task_3.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
